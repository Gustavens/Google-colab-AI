{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1DLuuJDDWnvJmgkyDp6kK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavens/Google-colab-AI/blob/main/Act_3_T4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Materia: PLN, Visión y Ética Computacional\n",
        "\n",
        "Fecha: 01 de Junio de 2025"
      ],
      "metadata": {
        "id": "usmiyUiPLMNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "rj3VV4O2AUy8"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 1. INSTALACIÓN E IMPORTACIÓN DE LIBRERÍAS\n",
        "# ==============================================================================\n",
        "# pip install nltk\n",
        "\n",
        "import nltk\n",
        "import pprint\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import hmm\n",
        "import pprint # Para imprimir las estructuras de datos de forma legible\n",
        "\n",
        "# Descarga de paquetes de NLTK necesarios para la actividad\n",
        "nltk.download('brown', quiet=True)\n",
        "nltk.download('treebank', quiet=True)\n",
        "nltk.download('tagsets', quiet=True)\n",
        "nltk.download('universal_tagset', quiet=True)\n",
        "\n",
        "\n",
        "# Inicializar PrettyPrinter para una mejor visualización de los resultados\n",
        "pp = pprint.PrettyPrinter(indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga de paquete treebank\n",
        "#Para aplicar en el modelo a entrenar con una cantidad de las primeras 3000 muestras.\n",
        "nltk.download('treebank')\n",
        "train_data = treebank.tagged_sents()[0:3000]\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYpGp2PVBAq_",
        "outputId": "76dd646c-2bfb-40c4-91ab-d25003fcda35"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('tagsets_json')\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPem_ZJvBDEC",
        "outputId": "be6ae4a1-fde0-4697-9d3b-03dcd24072ea"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets_json is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. EXPLORACIÓN DEL CORPUS Y TAGSETS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- 2.1. Exploración del conjunto de etiquetas Penn Treebank ---\")\n",
        "# La instrucción muestra las etiquetas del conjunto Penn Treebank y su significado.\n",
        "nltk.help.upenn_tagset()\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "print(\"--- 2.2. Exploración de la categoría 'news' del corpus Brown (Tagset por defecto) ---\")\n",
        "# Se obtienen las oraciones etiquetadas de la categoría 'news'\n",
        "oraciones_news_brown = brown.tagged_sents(categories='news')\n",
        "print(\"Ejemplo de oración etiquetada con el tagset por defecto (Penn Treebank):\")\n",
        "pp.pprint(oraciones_news_brown[0])\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "print(\"--- 2.3. Exploración de la categoría 'news' con Tagset Universal ---\")\n",
        "# Se repite el paso anterior, pero especificando el tagset 'universal'\n",
        "oraciones_news_universal = brown.tagged_sents(categories='news', tagset='universal')\n",
        "print(\"Ejemplo de oración etiquetada con el tagset 'universal':\")\n",
        "pp.pprint(oraciones_news_universal[0])\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QevH3ERPAmNt",
        "outputId": "3e7185a0-d314-436b-8828-e7118cc2cdf4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2.1. Exploración del conjunto de etiquetas Penn Treebank ---\n",
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n",
            "\n",
            "================================================================================\n",
            "\n",
            "--- 2.2. Exploración de la categoría 'news' del corpus Brown (Tagset por defecto) ---\n",
            "Ejemplo de oración etiquetada con el tagset por defecto (Penn Treebank):\n",
            "[   ('The', 'AT'),\n",
            "    ('Fulton', 'NP-TL'),\n",
            "    ('County', 'NN-TL'),\n",
            "    ('Grand', 'JJ-TL'),\n",
            "    ('Jury', 'NN-TL'),\n",
            "    ('said', 'VBD'),\n",
            "    ('Friday', 'NR'),\n",
            "    ('an', 'AT'),\n",
            "    ('investigation', 'NN'),\n",
            "    ('of', 'IN'),\n",
            "    (\"Atlanta's\", 'NP$'),\n",
            "    ('recent', 'JJ'),\n",
            "    ('primary', 'NN'),\n",
            "    ('election', 'NN'),\n",
            "    ('produced', 'VBD'),\n",
            "    ('``', '``'),\n",
            "    ('no', 'AT'),\n",
            "    ('evidence', 'NN'),\n",
            "    (\"''\", \"''\"),\n",
            "    ('that', 'CS'),\n",
            "    ('any', 'DTI'),\n",
            "    ('irregularities', 'NNS'),\n",
            "    ('took', 'VBD'),\n",
            "    ('place', 'NN'),\n",
            "    ('.', '.')]\n",
            "\n",
            "================================================================================\n",
            "\n",
            "--- 2.3. Exploración de la categoría 'news' con Tagset Universal ---\n",
            "Ejemplo de oración etiquetada con el tagset 'universal':\n",
            "[   ('The', 'DET'),\n",
            "    ('Fulton', 'NOUN'),\n",
            "    ('County', 'NOUN'),\n",
            "    ('Grand', 'ADJ'),\n",
            "    ('Jury', 'NOUN'),\n",
            "    ('said', 'VERB'),\n",
            "    ('Friday', 'NOUN'),\n",
            "    ('an', 'DET'),\n",
            "    ('investigation', 'NOUN'),\n",
            "    ('of', 'ADP'),\n",
            "    (\"Atlanta's\", 'NOUN'),\n",
            "    ('recent', 'ADJ'),\n",
            "    ('primary', 'NOUN'),\n",
            "    ('election', 'NOUN'),\n",
            "    ('produced', 'VERB'),\n",
            "    ('``', '.'),\n",
            "    ('no', 'DET'),\n",
            "    ('evidence', 'NOUN'),\n",
            "    (\"''\", '.'),\n",
            "    ('that', 'ADP'),\n",
            "    ('any', 'DET'),\n",
            "    ('irregularities', 'NOUN'),\n",
            "    ('took', 'VERB'),\n",
            "    ('place', 'NOUN'),\n",
            "    ('.', '.')]\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. IMPLEMENTACIÓN DE LA FUNCIÓN DE DISTRIBUCIÓN DE FRECUENCIAS\n",
        "# ==============================================================================\n",
        "\n",
        "def explora_tagset_fd(genero, tagset):\n",
        "    \"\"\"\n",
        "    Calcula la distribución de frecuencias de las etiquetas POS dentro de un género del corpus Brown.\n",
        "\n",
        "    :parametro genero: Un genero dentro del corpus Brown\n",
        "    :type genero: str o iterable(str) o None\n",
        "    :parametro tagset: El nombre del tagset dentro del corpus Brown\n",
        "    :type tagset: str o None (el default es 'brown')\n",
        "    :return: cantidad de tipos de etiquetas, top 10 de etiquetas\n",
        "    :rtype: tuple(int, list(tuple(str, int)))\n",
        "    \"\"\"\n",
        "    print(f\"--- Calculando distribución para Género: '{genero}', Tagset: '{tagset or 'default'}' ---\")\n",
        "\n",
        "    # 1. Obtener las palabras etiquetadas del corpus para el género y tagset especificados.\n",
        "    palabras_etiq = brown.tagged_words(categories=genero, tagset=tagset)\n",
        "\n",
        "    # 2. Convertir la lista de palabras etiquetadas a una lista de solo etiquetas.\n",
        "    tags = [tag for (word, tag) in palabras_etiq]\n",
        "\n",
        "    # 3. Calcular la distribución de frecuencias de las etiquetas.\n",
        "    etiqFD = nltk.FreqDist(tags)\n",
        "\n",
        "    # 4. Calcular la cantidad de tipos de etiquetas únicas.\n",
        "    num_etiquetas = len(etiqFD)\n",
        "\n",
        "    # 5. Obtener las 10 etiquetas más frecuentes y su frecuencia.\n",
        "    top_tags = etiqFD.most_common(10)\n",
        "\n",
        "    return num_etiquetas, top_tags\n",
        "\n",
        "# --- Pruebas de la función explora_tagset_fd ---\n",
        "print(\"--- 3.1. Probando la función explora_tagset_fd ---\")\n",
        "\n",
        "# Prueba 1: Categoría 'news' con tagset por defecto (Penn Treebank)\n",
        "num_etiq_news, top_news = explora_tagset_fd('news', None)\n",
        "print(\"Resultados para 'news' (Penn Treebank):\")\n",
        "print(f\"Número total de tipos de etiquetas: {num_etiq_news}\")\n",
        "print(\"Top 10 etiquetas más frecuentes:\")\n",
        "pp.pprint(top_news)\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Prueba 2: Categoría 'science_fiction' con tagset 'universal'\n",
        "num_etiq_sf, top_sf = explora_tagset_fd('science_fiction', 'universal')\n",
        "print(\"Resultados para 'science_fiction' (universal):\")\n",
        "print(f\"Número total de tipos de etiquetas: {num_etiq_sf}\")\n",
        "print(\"Top 10 etiquetas más frecuentes:\")\n",
        "pp.pprint(top_sf)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiBI6ZCiBOAw",
        "outputId": "7654f481-1ca2-4960-edc5-942a41eb511d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3.1. Probando la función explora_tagset_fd ---\n",
            "--- Calculando distribución para Género: 'news', Tagset: 'default' ---\n",
            "Resultados para 'news' (Penn Treebank):\n",
            "Número total de tipos de etiquetas: 218\n",
            "Top 10 etiquetas más frecuentes:\n",
            "[   ('NN', 13162),\n",
            "    ('IN', 10616),\n",
            "    ('AT', 8893),\n",
            "    ('NP', 6866),\n",
            "    (',', 5133),\n",
            "    ('NNS', 5066),\n",
            "    ('.', 4452),\n",
            "    ('JJ', 4392),\n",
            "    ('CC', 2664),\n",
            "    ('VBD', 2524)]\n",
            "----------------------------------------\n",
            "--- Calculando distribución para Género: 'science_fiction', Tagset: 'universal' ---\n",
            "Resultados para 'science_fiction' (universal):\n",
            "Número total de tipos de etiquetas: 12\n",
            "Top 10 etiquetas más frecuentes:\n",
            "[   ('NOUN', 2747),\n",
            "    ('VERB', 2579),\n",
            "    ('.', 2428),\n",
            "    ('DET', 1582),\n",
            "    ('ADP', 1451),\n",
            "    ('PRON', 934),\n",
            "    ('ADJ', 929),\n",
            "    ('ADV', 828),\n",
            "    ('PRT', 483),\n",
            "    ('CONJ', 416)]\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. ENTRENAMIENTO Y EVALUACIÓN DE UN MODELO HMM\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Ayuda de la clase HiddenMarkovModelTagger ---\")\n",
        "# Se utiliza help para entender el funcionamiento de la clase\n",
        "# help(nltk.tag.hmm.HiddenMarkovModelTagger)\n",
        "print(\"La función help() se ha comentado para evitar un output extenso.\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "def entrenamientoHMM(oracion, tamanio):\n",
        "    \"\"\"\n",
        "    Crea un etiquetador HMM de la categoria news del corpus Brown y se evalua con una oracion de prueba.\n",
        "\n",
        "    :parametro oracion: Una oración sin etiquetar\n",
        "    :type oracion: list(str)\n",
        "    :parametro tamano: Número de oraciones para entrenar\n",
        "    :type tamano: int\n",
        "    :return: El objeto etiquetador, la oración de pruebas con etiquetas y la precisión (accuracy).\n",
        "    :rtype: tuple(nltk.tag.hmm.HiddenMarkovModelTagger, list(tuple(str,str)), float)\n",
        "    \"\"\"\n",
        "    oraciones_etiq = brown.tagged_sents(categories='news', tagset='universal')\n",
        "\n",
        "    # Datos de entrenamiento\n",
        "    datos_train = oraciones_etiq[:tamanio]\n",
        "\n",
        "    # Datos de prueba (las siguientes 500 oraciones para evitar solapamiento)\n",
        "    datos_test = oraciones_etiq[tamanio : tamanio + 500]\n",
        "\n",
        "    # Entrenar el modelo HiddenMarkovModelTagger con el método train().\n",
        "    tagger = nltk.tag.hmm.HiddenMarkovModelTagger.train(datos_train)\n",
        "\n",
        "    # Utilizar el etiquetador para etiquetar la oración de prueba.\n",
        "    oracion_etiqueta_hmm = tagger.tag(oracion)\n",
        "\n",
        "    # Evaluar la precisión (accuracy) con los datos de prueba.\n",
        "    acc = tagger.accuracy(datos_test)\n",
        "\n",
        "    return tagger, oracion_etiqueta_hmm, acc\n",
        "\n",
        "def evaluarHMM():\n",
        "    \"\"\"\n",
        "    Función para evaluar el rendimiento del HMM con diferentes tamaños de conjunto de entrenamiento.\n",
        "    \"\"\"\n",
        "    oraciones_etiq = brown.tagged_sents(categories='news', tagset='universal')\n",
        "    # Se toma una oración de ejemplo para probar el etiquetado\n",
        "    oracion_prueba = [word for word, tag in oraciones_etiq[505]]\n",
        "    print(f\"Oración de prueba: {' '.join(oracion_prueba)}\\n\")\n",
        "\n",
        "    # --- Evaluación con 500 oraciones ---\n",
        "    tagger_500, oracion_etiquetada_500, acc_500 = entrenamientoHMM(oracion_prueba, 500)\n",
        "    print('--- Entrenando el modelo con 500 oraciones... ---')\n",
        "    print('Oración etiquetada con el modelo:')\n",
        "    pp.pprint(oracion_etiquetada_500)\n",
        "    print(f'Accuracy del conjunto de pruebas: {100.0 * acc_500:.4f}%\\n')\n",
        "\n",
        "    # --- Evaluación con 3000 oraciones ---\n",
        "    tagger_3000, oracion_etiquetada_3000, acc_3000 = entrenamientoHMM(oracion_prueba, 3000)\n",
        "    print('--- Entrenando el modelo con 3000 oraciones... ---')\n",
        "    print('Oración etiquetada con el modelo:')\n",
        "    pp.pprint(oracion_etiquetada_3000)\n",
        "    print(f'Accuracy del conjunto de pruebas: {100.0 * acc_3000:.4f}%')\n",
        "\n",
        "# --- Ejecutar la evaluación del HMM ---\n",
        "print(\"--- 4.2. Evaluación del rendimiento del Modelo HMM ---\")\n",
        "evaluarHMM()\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdgDqh3tBgVv",
        "outputId": "69c39022-6650-4a23-8799-ae3e95452d13"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ayuda de la clase HiddenMarkovModelTagger ---\n",
            "La función help() se ha comentado para evitar un output extenso.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "--- 4.2. Evaluación del rendimiento del Modelo HMM ---\n",
            "Oración de prueba: He said Mitchell is against the centralization of government in Washington but looks to the Kennedy Administration for aid to meet New Jersey school and transportation crises .\n",
            "\n",
            "--- Entrenando el modelo con 500 oraciones... ---\n",
            "Oración etiquetada con el modelo:\n",
            "[   ('He', 'PRON'),\n",
            "    ('said', 'VERB'),\n",
            "    ('Mitchell', 'NOUN'),\n",
            "    ('is', 'VERB'),\n",
            "    ('against', 'ADP'),\n",
            "    ('the', 'DET'),\n",
            "    ('centralization', 'NOUN'),\n",
            "    ('of', 'ADP'),\n",
            "    ('government', 'NOUN'),\n",
            "    ('in', 'ADP'),\n",
            "    ('Washington', 'NOUN'),\n",
            "    ('but', 'CONJ'),\n",
            "    ('looks', 'NOUN'),\n",
            "    ('to', 'ADP'),\n",
            "    ('the', 'DET'),\n",
            "    ('Kennedy', 'NOUN'),\n",
            "    ('Administration', '.'),\n",
            "    ('for', 'ADP'),\n",
            "    ('aid', 'NOUN'),\n",
            "    ('to', 'PRT'),\n",
            "    ('meet', 'VERB'),\n",
            "    ('New', 'ADJ'),\n",
            "    ('Jersey', 'NOUN'),\n",
            "    ('school', 'NOUN'),\n",
            "    ('and', 'CONJ'),\n",
            "    ('transportation', 'ADJ'),\n",
            "    ('crises', 'NOUN'),\n",
            "    ('.', '.')]\n",
            "Accuracy del conjunto de pruebas: 83.0633%\n",
            "\n",
            "--- Entrenando el modelo con 3000 oraciones... ---\n",
            "Oración etiquetada con el modelo:\n",
            "[   ('He', 'PRON'),\n",
            "    ('said', 'VERB'),\n",
            "    ('Mitchell', 'NOUN'),\n",
            "    ('is', 'VERB'),\n",
            "    ('against', 'ADP'),\n",
            "    ('the', 'DET'),\n",
            "    ('centralization', 'NOUN'),\n",
            "    ('of', 'ADP'),\n",
            "    ('government', 'NOUN'),\n",
            "    ('in', 'ADP'),\n",
            "    ('Washington', 'NOUN'),\n",
            "    ('but', 'CONJ'),\n",
            "    ('looks', 'VERB'),\n",
            "    ('to', 'ADP'),\n",
            "    ('the', 'DET'),\n",
            "    ('Kennedy', 'NOUN'),\n",
            "    ('Administration', 'NOUN'),\n",
            "    ('for', 'ADP'),\n",
            "    ('aid', 'NOUN'),\n",
            "    ('to', 'PRT'),\n",
            "    ('meet', 'VERB'),\n",
            "    ('New', 'ADJ'),\n",
            "    ('Jersey', 'NOUN'),\n",
            "    ('school', 'NOUN'),\n",
            "    ('and', 'CONJ'),\n",
            "    ('transportation', 'NOUN'),\n",
            "    ('crises', 'NOUN'),\n",
            "    ('.', '.')]\n",
            "Accuracy del conjunto de pruebas: 85.4816%\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. MEJORA DEL MODELO HMM CON EL CORPUS TREEBANK\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- 5. Mejora del Modelo con Corpus Treebank ---\")\n",
        "\n",
        "# El bajo rendimiento inicial puede deberse a la cantidad y variabilidad de los datos.\n",
        "# Se utilizará el corpus Treebank, que es un estándar para el entrenamiento de etiquetadores POS.\n",
        "\n",
        "# División de datos: 3000 para entrenamiento y el resto para pruebas.\n",
        "train_data = treebank.tagged_sents()[:3000]\n",
        "test_data = treebank.tagged_sents()[3000:]\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento (Treebank): {len(train_data)}\")\n",
        "print(f\"Tamaño del conjunto de pruebas (Treebank): {len(test_data)}\\n\")\n",
        "\n",
        "\n",
        "# Entrenar un nuevo etiquetador HMM con los datos de Treebank\n",
        "print(\"Entrenando el nuevo modelo HMM con Treebank...\")\n",
        "tagger_treebank = nltk.tag.hmm.HiddenMarkovModelTagger.train(train_data)\n",
        "print(\"Modelo entrenado.\\n\")\n",
        "\n",
        "# Evaluar el nuevo modelo\n",
        "# Nota: El método .evaluate() está obsoleto, se usa .accuracy()\n",
        "accuracy_treebank = tagger_treebank.accuracy(test_data)\n",
        "\n",
        "print(f\"Accuracy del modelo con Treebank: {accuracy_treebank*100:.4f}%\")\n",
        "\n",
        "# Probar el etiquetado en una oración de ejemplo\n",
        "oracion_ejemplo = \"This is a simple test for our new HMM tagger\".split()\n",
        "etiquetas_ejemplo = tagger_treebank.tag(oracion_ejemplo)\n",
        "\n",
        "print(\"\\nEjemplo de etiquetado con el modelo de Treebank:\")\n",
        "pp.pprint(etiquetas_ejemplo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKNwZIBgB4tl",
        "outputId": "90f9d879-5a49-4648-d6ca-376402152aa2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Mejora del Modelo con Corpus Treebank ---\n",
            "Tamaño del conjunto de entrenamiento (Treebank): 3000\n",
            "Tamaño del conjunto de pruebas (Treebank): 914\n",
            "\n",
            "Entrenando el nuevo modelo HMM con Treebank...\n",
            "Modelo entrenado.\n",
            "\n",
            "Accuracy del modelo con Treebank: 89.8424%\n",
            "\n",
            "Ejemplo de etiquetado con el modelo de Treebank:\n",
            "[   ('This', 'DT'),\n",
            "    ('is', 'VBZ'),\n",
            "    ('a', 'DT'),\n",
            "    ('simple', 'JJ'),\n",
            "    ('test', 'NN'),\n",
            "    ('for', 'IN'),\n",
            "    ('our', 'PRP$'),\n",
            "    ('new', 'JJ'),\n",
            "    ('HMM', '.'),\n",
            "    ('tagger', \"''\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('corpora/brown')\n",
        "    nltk.data.find('taggers/universal_tagset')\n",
        "except nltk.downloader.DownloadError:\n",
        "    print(\"Descargando corpus 'brown' y 'universal_tagset' de NLTK...\")\n",
        "    nltk.download('brown', quiet=True)\n",
        "    nltk.download('universal_tagset', quiet=True)\n",
        "    print(\"Descarga completada.\")"
      ],
      "metadata": {
        "id": "MOXiNqV9ENZg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. FUNCIÓN PARA ENTRENAR Y EVALUAR EL ETIQUETADOR HMM\n",
        "# ==============================================================================\n",
        "\n",
        "def train_and_evaluate_hmm_brown_news():\n",
        "    \"\"\"\n",
        "    Esta función implementa tres tareas utilizando la categoría 'news' del corpus Brown:\n",
        "    1. Entrena un etiquetador HMM con el conjunto de datos de entrenamiento.\n",
        "    2. Con el modelo entrenado, etiqueta una oración de ejemplo.\n",
        "    3. Evalúa el modelo entrenado en el conjunto de pruebas.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Carga y Preparación de Datos (Corpus Brown - Categoría 'news') ---\")\n",
        "\n",
        "    # Cargar las oraciones etiquetadas de la categoría 'news' del corpus Brown.\n",
        "    # nltk.tag.hmm.HiddenMarkovModelTagger.train espera tuplas (palabra, etiqueta).\n",
        "    # brown.tagged_sents() ya proporciona este formato.\n",
        "    tagged_sents = brown.tagged_sents(categories='news')\n",
        "\n",
        "    # Dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "    # Usaremos una división 90/10 (90% para entrenamiento, 10% para prueba).\n",
        "    # La división se hace por oraciones.\n",
        "    split_point = int(len(tagged_sents) * 0.9)\n",
        "    train_data = tagged_sents[:split_point]\n",
        "    test_data = tagged_sents[split_point:]\n",
        "\n",
        "    print(f\"Tamaño total de oraciones en 'news': {len(tagged_sents)}\")\n",
        "    print(f\"Tamaño del conjunto de entrenamiento: {len(train_data)} oraciones\")\n",
        "    print(f\"Tamaño del conjunto de pruebas: {len(test_data)} oraciones\")\n",
        "\n",
        "    print(\"\\n--- 2. Entrenamiento del Etiquetador HMM ---\")\n",
        "    # Crear y entrenar el etiquetador HMM.\n",
        "    # El método .train() aprende las probabilidades de transición y emisión\n",
        "    # a partir de los datos de entrenamiento.\n",
        "    tagger = hmm.HiddenMarkovModelTagger.train(train_data)\n",
        "    print(\"Modelo HMM entrenado.\")\n",
        "\n",
        "    print(\"\\n--- 3. Etiquetado de una Oración de Ejemplo ---\")\n",
        "    # Elegir una oración simple para demostrar el etiquetado.\n",
        "    # ¡Importante! La función tag() espera una lista de palabras (strings), no tuplas.\n",
        "    sample_sentence = \"The quick brown fox jumps over the lazy dog\".split()\n",
        "\n",
        "    # Etiquetar la oración de ejemplo con el modelo entrenado.\n",
        "    tagged_sample = tagger.tag(sample_sentence)\n",
        "\n",
        "    print(f\"Oración original: {' '.join(sample_sentence)}\")\n",
        "    print(\"Oración de ejemplo etiquetada por el HMM:\")\n",
        "    pprint.pprint(tagged_sample)\n",
        "\n",
        "    print(\"\\n--- 4. Evaluación del Modelo Entrenado ---\")\n",
        "    # Evaluar el modelo en el conjunto de pruebas.\n",
        "    # El método .evaluate() calcula la precisión del etiquetador.\n",
        "    # Se recomienda usar .accuracy() en versiones más recientes de NLTK.\n",
        "    # La advertencia de DeprecationWarning en `evaluate()` indica que `accuracy()`\n",
        "    # es la forma preferida. Sin embargo, para mantener la consistencia con ejemplos\n",
        "    # que podrían usar `.evaluate()`, lo mantendremos así, pero se puede cambiar.\n",
        "    accuracy = tagger.evaluate(test_data)\n",
        "    print(f\"Accuracy del modelo HMM en el corpus Brown 'news': {accuracy:.4f}\") # Formato a 4 decimales\n",
        "\n",
        "    print(\"\\n--- Proceso Completado ---\")\n"
      ],
      "metadata": {
        "id": "8koW4wNbEl-v"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. EJECUCIÓN DE LA FUNCIÓN\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_evaluate_hmm_brown_news()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6fQgXxuEoeT",
        "outputId": "470e9ddd-55fa-44de-f02c-16589fbdbe3a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Carga y Preparación de Datos (Corpus Brown - Categoría 'news') ---\n",
            "Tamaño total de oraciones en 'news': 4623\n",
            "Tamaño del conjunto de entrenamiento: 4160 oraciones\n",
            "Tamaño del conjunto de pruebas: 463 oraciones\n",
            "\n",
            "--- 2. Entrenamiento del Etiquetador HMM ---\n",
            "Modelo HMM entrenado.\n",
            "\n",
            "--- 3. Etiquetado de una Oración de Ejemplo ---\n",
            "Oración original: The quick brown fox jumps over the lazy dog\n",
            "Oración de ejemplo etiquetada por el HMM:\n",
            "[('The', 'AT'),\n",
            " ('quick', 'JJ'),\n",
            " ('brown', 'NN'),\n",
            " ('fox', 'BEDZ'),\n",
            " ('jumps', 'VBN'),\n",
            " ('over', 'IN'),\n",
            " ('the', 'AT'),\n",
            " ('lazy', 'JJ'),\n",
            " ('dog', 'NN')]\n",
            "\n",
            "--- 4. Evaluación del Modelo Entrenado ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-9c1cecb22624>:56: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy del modelo HMM en el corpus Brown 'news': 0.8506\n",
            "\n",
            "--- Proceso Completado ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import hmm\n",
        "import pprint # Para imprimir las estructuras de datos de forma legible\n",
        "from nltk.metrics import ConfusionMatrix # Importar ConfusionMatrix específicamente\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/brown')\n",
        "    nltk.data.find('taggers/universal_tagset')\n",
        "except nltk.downloader.DownloadError:\n",
        "    print(\"Descargando corpus 'brown' y 'universal_tagset' de NLTK...\")\n",
        "    nltk.download('brown', quiet=True)\n",
        "    nltk.download('universal_tagset', quiet=True)\n",
        "    print(\"Descarga completada.\")"
      ],
      "metadata": {
        "id": "YlXhgHPWGJni"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Glosario de Acrónimos (Etiquetas POS - Corpus Brown de NLTK)\n",
        "\n",
        "Categorías Generales:\n",
        "* AT: Article (Artículo)\n",
        "* NN: Noun, singular (Sustantivo, singular)\n",
        "* NNS: Noun, plural (Sustantivo, plural)\n",
        "* NP: Proper Noun, singular (Nombre Propio, singular)\n",
        "* NPS: Proper Noun, plural (Nombre Propio, plural)\n",
        "* JJ: Adjective (Adjetivo)\n",
        "* JJR: Adjective, comparative (Adjetivo, comparativo)\n",
        "* JJS: Adjective, superlative (Adjetivo, superlativo)\n",
        "* RB: Adverb (Adverbio)\n",
        "* RBR: Adverb, comparative (Adverbio, comparativo)\n",
        "* RBS: Adverb, superlative (Adverbio, superlativo)\n",
        "* RN: Nominal adverb (Adverbio nominal)\n",
        "* RP: Adverb, particle (Partícula adverbial)\n",
        "* IN: Preposition/conjunction (Preposición / Conjunción)\n",
        "* CS: Conjunction, subordinating (Conjunción subordinante)\n",
        "* CC: Conjunction, coordinating (Conjunción coordinante)\n",
        "* TO: To (preposición \"a\" o marcador de infinitivo)\n",
        "* VB: Verb, base form (Verbo, forma base)\n",
        "* VBD: Verb, past tense (Verbo, pasado)\n",
        "* VBG: Verb, gerund/present participle (Verbo, gerundio / participio presente)\n",
        "* VBN: Verb, past participle (Verbo, participio pasado)\n",
        "* VBP: Verb, non-3rd person singular present (Verbo, presente, no 3ª persona singular)\n",
        "* VBZ: Verb, 3rd person singular present (Verbo, presente, 3ª persona singular)\n",
        "* MD: Modal (Verbo modal: can, could, may, might, must, shall, should, will, would)\n",
        "* FW: Foreign word (Palabra extranjera)\n",
        "* EX: Existential `there` (Existencial \"there\" en construcciones como \"there is\")\n",
        "* UH: Interjection (Interjección)\n",
        "* SYM: Symbol (Símbolo)\n",
        "* OD: Ordinal number (Número ordinal: first, second, third)\n",
        "\n",
        "Verbos Auxiliares Específicos:\n",
        "* BE: Be (forma base del verbo \"ser/estar\")\n",
        "* BED: Be, past tense, 2nd person singular, 1st and 3rd plural (were)\n",
        "* BEDZ: Be, past tense, 1st and 3rd person singular (was)\n",
        "* BEG: Be, present participle (being)\n",
        "* BEM: Be, present tense, 1st person singular (am)\n",
        "* BEN: Be, past participle (been)\n",
        "* BER: Be, present tense, 2nd person singular or 1st and 3rd plural (are)\n",
        "* BEZ: Be, present tense, 3rd person singular (is)\n",
        "* DO: Do (forma base del verbo \"hacer/auxiliar de negación/pregunta\")\n",
        "* DOD: Do, past tense (did)\n",
        "* DOZ: Do, present tense, 3rd person singular (does)\n",
        "* HV: Have (forma base del verbo \"tener/auxiliar de perfecto\")\n",
        "* HVD: Have, past tense (had)\n",
        "* HVG: Have, present participle (having)\n",
        "* HVN: Have, past participle (had)\n",
        "* HVZ: Have, present tense, 3rd person singular (has)\n",
        "\n",
        "Pronombres:\n",
        "* PP$: Possessive pronoun (Pronombre posesivo: mine, yours)\n",
        "* PP$$: Possessive pronoun, second (Pronombre posesivo, segunda forma: hers, his)\n",
        "* PPO: Objective pronoun (Pronombre objetivo: me, him, her, us, them)\n",
        "* PPS: Nominal 3rd singular non-human pronoun (Pronombre nominativo, 3ª pers. singular, no humano: it)\n",
        "* PPSS: Nominal plural pronoun (Pronombre nominativo, plural: we, they)\n",
        "* PN: Preposition, non-predicative (Pronombre, no predicativo - a veces se usa para 'one')\n",
        "* PPL: Singular personal pronoun (Pronombre personal singular: I, you, he, she)\n",
        "* PPLS: Plural personal pronoun (Pronombre personal plural: we, you, they)\n",
        "\n",
        "Adjetivos/Adverbios Específicos:\n",
        "* AP: Adjective, predicative (Adjetivo, predicativo)\n",
        "* QL: Qualitative adjective (Adjetivo cualitativo)\n",
        "* QLP: Qualitative adjective, plural (Adjetivo cualitativo, plural)\n",
        "* QP: Quantifier (Cuantificador)\n",
        "* RB$: Possessive adverb (Adverbio posesivo: e.g., here's, there's)\n",
        "\n",
        "Wh-palabras:\n",
        "* WDT: Wh-determiner (what, which, whatever)\n",
        "* WP: Wh-pronoun (who, what, which)\n",
        "* WPS: Possessive wh-pronoun (whose)\n",
        "* WRB: Wh-adverb (where, when, why, how)\n",
        "\n",
        "Marcadores de Formato/Estilo:\n",
        "* -HL: Headline (Indica que la palabra aparece en un titular)\n",
        "* -TL: Title (Indica que la palabra aparece en un título)\n",
        "\n",
        "Puntuación:\n",
        "* . : End of sentence punctuation (Puntuación de fin de oración)\n",
        "* , : Comma (Coma)\n",
        "* :/: : Colon/semicolon (Dos puntos / Punto y coma)\n",
        "* ( ) : Parentheses (Paréntesis)\n",
        "* `` : Opening quote (Comilla de apertura)\n",
        "* '' : Closing quote (Comilla de cierre)"
      ],
      "metadata": {
        "id": "bLPny5hOK2Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. FUNCIÓN PARA ENTRENAR Y EVALUAR EL ETIQUETADOR HMM (Actualizada para retornar tagger y test_data)\n",
        "# ==============================================================================\n",
        "\n",
        "def train_and_evaluate_hmm_brown_news():\n",
        "    \"\"\"\n",
        "    Esta función entrena un etiquetador HMM con la categoría 'news' del corpus Brown,\n",
        "    etiqueta una oración de ejemplo y evalúa el modelo globalmente.\n",
        "    Retorna el tagger entrenado y el conjunto de datos de prueba para evaluaciones posteriores.\n",
        "    \"\"\"\n",
        "    print(\"--- 1. Carga y Preparación de Datos (Corpus Brown - Categoría 'news') ---\")\n",
        "\n",
        "    tagged_sents = brown.tagged_sents(categories='news')\n",
        "\n",
        "    # Dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "    # Usaremos una división 90/10 (90% para entrenamiento, 10% para prueba).\n",
        "    split_point = int(len(tagged_sents) * 0.9)\n",
        "    train_data = tagged_sents[:split_point]\n",
        "    test_data = tagged_sents[split_point:]\n",
        "\n",
        "    print(f\"Tamaño total de oraciones en 'news': {len(tagged_sents)}\")\n",
        "    print(f\"Tamaño del conjunto de entrenamiento: {len(train_data)} oraciones\")\n",
        "    print(f\"Tamaño del conjunto de pruebas: {len(test_data)} oraciones\")\n",
        "\n",
        "    print(\"\\n--- 2. Entrenamiento del Etiquetador HMM ---\")\n",
        "    tagger = hmm.HiddenMarkovModelTagger.train(train_data)\n",
        "    print(\"Modelo HMM entrenado.\")\n",
        "\n",
        "    print(\"\\n--- 3. Etiquetado de una Oración de Ejemplo (general) ---\")\n",
        "    sample_sentence = \"The quick brown fox jumps over the lazy dog\".split()\n",
        "    tagged_sample = tagger.tag(sample_sentence)\n",
        "    print(\"Oración de ejemplo (general) etiquetada:\")\n",
        "    pprint.pprint(tagged_sample)\n",
        "\n",
        "    print(\"\\n--- 4. Evaluación GLOBAL del Modelo Entrenado ---\")\n",
        "    # Usa tagger.accuracy(test_data) en versiones más recientes de NLTK si evaluate() da un DeprecationWarning\n",
        "    accuracy = tagger.evaluate(test_data)\n",
        "    print(f\"Accuracy GLOBAL del modelo HMM en el corpus Brown 'news': {accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Proceso de Entrenamiento y Evaluación Global Completado ---\")\n",
        "    # Retornamos el tagger y los datos de prueba para usarlos en la evaluación individual\n",
        "    return tagger, test_data\n"
      ],
      "metadata": {
        "id": "SBXKxoMuF1OW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. FUNCIÓN PARA EVALUAR UNA ORACIÓN INDIVIDUAL\n",
        "# ==============================================================================\n",
        "\n",
        "def evaluate_single_sentence_with_hmm(tagger, test_data, sentence_index):\n",
        "    \"\"\"\n",
        "    Evalúa una única oración del conjunto de pruebas utilizando un ConfusionMatrix\n",
        "    y las instrucciones sugeridas en la Figura 16.\n",
        "\n",
        "    Args:\n",
        "        tagger: El modelo HMM entrenado.\n",
        "        test_data: El conjunto de oraciones de prueba.\n",
        "        sentence_index (int): El índice de la oración a evaluar en test_data.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Evaluación detallada para la oración con índice {sentence_index} del conjunto de pruebas ---\")\n",
        "\n",
        "    # Verificar que el índice sea válido\n",
        "    if not (0 <= sentence_index < len(test_data)):\n",
        "        print(f\"Error: El índice {sentence_index} está fuera del rango válido \"\n",
        "              f\"de las oraciones de prueba (0 a {len(test_data) - 1}).\")\n",
        "        return\n",
        "\n",
        "    # 1. Obtener la oración real (etiquetada) del conjunto de pruebas\n",
        "    real_tagged_sentence = test_data[sentence_index]\n",
        "\n",
        "    # 2. Separar las palabras de las etiquetas reales (gold standard)\n",
        "    words_to_tag = [word for word, tag in real_tagged_sentence]\n",
        "    true_tags = [tag for word, tag in real_tagged_sentence]\n",
        "\n",
        "    print(f\"Oración original (palabras): {' '.join(words_to_tag)}\")\n",
        "    print(f\"Etiquetas reales (gold standard):\")\n",
        "    pprint.pprint(real_tagged_sentence)\n",
        "\n",
        "    # 3. Etiquetar la oración con el modelo HMM\n",
        "    predicted_tagged_sentence = tagger.tag(words_to_tag)\n",
        "\n",
        "    # 4. Extraer solo las etiquetas predichas\n",
        "    predicted_tags = [tag for word, tag in predicted_tagged_sentence]\n",
        "\n",
        "    print(f\"Etiquetas predichas por el modelo HMM:\")\n",
        "    pprint.pprint(predicted_tagged_sentence)\n",
        "\n",
        "    # 5. Crear y mostrar la matriz de confusión\n",
        "    # ConfusionMatrix toma dos listas de etiquetas: (referencia verdadera, predicciones)\n",
        "    print(\"\\nMatriz de Confusión para esta oración:\")\n",
        "    # La matriz de confusión es más útil para evaluar el desempeño de cada etiqueta\n",
        "    # sobre un conjunto más grande de datos, pero aquí se usa para visualizar\n",
        "    # los aciertos y errores en esta oración específica.\n",
        "    cm = ConfusionMatrix(true_tags, predicted_tags)\n",
        "    print(cm)\n",
        "\n",
        "    # Para una evaluación de precisión de esta oración específica:\n",
        "    correct_tags = sum(1 for true_t, pred_t in zip(true_tags, predicted_tags) if true_t == pred_t)\n",
        "    sentence_accuracy = correct_tags / len(true_tags) if true_tags else 0\n",
        "    print(f\"Precisión para esta oración específica: {sentence_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "qoktFmzpGP-f"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. EJECUCIÓN DEL FLUJO PRINCIPAL\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Primero, entrenamos el modelo HMM y obtenemos el tagger y los datos de prueba\n",
        "    trained_hmm_tagger, test_set_data = train_and_evaluate_hmm_brown_news()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" INICIANDO EVALUACIÓN DE ORACIONES INDIVIDUALES\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # --- PRUEBA CON DISTINTOS ÍNDICES ---\n",
        "    # Cambia estos índices para probar diferentes oraciones del conjunto de pruebas.\n",
        "    # Asegúrate de que los índices sean válidos (entre 0 y len(test_set_data) - 1).\n",
        "    indices_to_test = [0, 5, 76, 150, 200] # Ejemplo de índices para probar\n",
        "\n",
        "    for idx in indices_to_test:\n",
        "        evaluate_single_sentence_with_hmm(trained_hmm_tagger, test_set_data, idx)\n",
        "\n",
        "    # --- OPCIÓN: PERMITIR AL USUARIO INTRODUCIR ÍNDICES ---\n",
        "    # Descomenta el siguiente bloque si quieres probar interactivamente\n",
        "    # while True:\n",
        "    #     try:\n",
        "    #         user_index_str = input(\"\\nIntroduce un índice de oración para evaluar (o 'q' para salir): \")\n",
        "    #         if user_index_str.lower() == 'q':\n",
        "    #             break\n",
        "    #         user_index = int(user_index_str)\n",
        "    #         evaluate_single_sentence_with_hmm(trained_hmm_tagger, test_set_data, user_index)\n",
        "    #     except ValueError:\n",
        "    #         print(\"Entrada no válida. Por favor, introduce un número entero o 'q'.\")\n",
        "    #     except Exception as e:\n",
        "    #         print(f\"Ocurrió un error inesperado: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcLzVe0OGWBC",
        "outputId": "48f57571-4b35-45fe-9032-d254f39b6951"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Carga y Preparación de Datos (Corpus Brown - Categoría 'news') ---\n",
            "Tamaño total de oraciones en 'news': 4623\n",
            "Tamaño del conjunto de entrenamiento: 4160 oraciones\n",
            "Tamaño del conjunto de pruebas: 463 oraciones\n",
            "\n",
            "--- 2. Entrenamiento del Etiquetador HMM ---\n",
            "Modelo HMM entrenado.\n",
            "\n",
            "--- 3. Etiquetado de una Oración de Ejemplo (general) ---\n",
            "Oración de ejemplo (general) etiquetada:\n",
            "[('The', 'AT'),\n",
            " ('quick', 'JJ'),\n",
            " ('brown', 'NN'),\n",
            " ('fox', 'BEDZ'),\n",
            " ('jumps', 'VBN'),\n",
            " ('over', 'IN'),\n",
            " ('the', 'AT'),\n",
            " ('lazy', 'JJ'),\n",
            " ('dog', 'NN')]\n",
            "\n",
            "--- 4. Evaluación GLOBAL del Modelo Entrenado ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-aad219ff2ab1>:37: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy GLOBAL del modelo HMM en el corpus Brown 'news': 0.8506\n",
            "\n",
            "--- Proceso de Entrenamiento y Evaluación Global Completado ---\n",
            "\n",
            "================================================================================\n",
            " INICIANDO EVALUACIÓN DE ORACIONES INDIVIDUALES\n",
            "================================================================================\n",
            "\n",
            "\n",
            "--- Evaluación detallada para la oración con índice 0 del conjunto de pruebas ---\n",
            "Oración original (palabras): But in all its 175 years , not a single Negro student has entered its classrooms .\n",
            "Etiquetas reales (gold standard):\n",
            "[('But', 'CC'),\n",
            " ('in', 'IN'),\n",
            " ('all', 'ABN'),\n",
            " ('its', 'PP$'),\n",
            " ('175', 'CD'),\n",
            " ('years', 'NNS'),\n",
            " (',', ','),\n",
            " ('not', '*'),\n",
            " ('a', 'AT'),\n",
            " ('single', 'AP'),\n",
            " ('Negro', 'NP'),\n",
            " ('student', 'NN'),\n",
            " ('has', 'HVZ'),\n",
            " ('entered', 'VBN'),\n",
            " ('its', 'PP$'),\n",
            " ('classrooms', 'NNS'),\n",
            " ('.', '.')]\n",
            "Etiquetas predichas por el modelo HMM:\n",
            "[('But', 'CC'),\n",
            " ('in', 'IN'),\n",
            " ('all', 'ABN'),\n",
            " ('its', 'PP$'),\n",
            " ('175', 'JJ'),\n",
            " ('years', 'NNS'),\n",
            " (',', ','),\n",
            " ('not', '*'),\n",
            " ('a', 'AT'),\n",
            " ('single', 'AP'),\n",
            " ('Negro', 'NP'),\n",
            " ('student', 'NN'),\n",
            " ('has', 'HVZ'),\n",
            " ('entered', 'VBN'),\n",
            " ('its', 'PP$'),\n",
            " ('classrooms', 'NN'),\n",
            " ('.', '.')]\n",
            "\n",
            "Matriz de Confusión para esta oración:\n",
            "    |       A         H       N   P V |\n",
            "    |       B A A C C V I J N N N P B |\n",
            "    | * , . N P T C D Z N J N S P $ N |\n",
            "----+---------------------------------+\n",
            "  * |<1>. . . . . . . . . . . . . . . |\n",
            "  , | .<1>. . . . . . . . . . . . . . |\n",
            "  . | . .<1>. . . . . . . . . . . . . |\n",
            "ABN | . . .<1>. . . . . . . . . . . . |\n",
            " AP | . . . .<1>. . . . . . . . . . . |\n",
            " AT | . . . . .<1>. . . . . . . . . . |\n",
            " CC | . . . . . .<1>. . . . . . . . . |\n",
            " CD | . . . . . . .<.>. . 1 . . . . . |\n",
            "HVZ | . . . . . . . .<1>. . . . . . . |\n",
            " IN | . . . . . . . . .<1>. . . . . . |\n",
            " JJ | . . . . . . . . . .<.>. . . . . |\n",
            " NN | . . . . . . . . . . .<1>. . . . |\n",
            "NNS | . . . . . . . . . . . 1<1>. . . |\n",
            " NP | . . . . . . . . . . . . .<1>. . |\n",
            "PP$ | . . . . . . . . . . . . . .<2>. |\n",
            "VBN | . . . . . . . . . . . . . . .<1>|\n",
            "----+---------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "Precisión para esta oración específica: 0.8824\n",
            "\n",
            "--- Evaluación detallada para la oración con índice 5 del conjunto de pruebas ---\n",
            "Oración original (palabras): The university rejected them on a variety of pretexts , but was careful never to mention the color of their skins .\n",
            "Etiquetas reales (gold standard):\n",
            "[('The', 'AT'),\n",
            " ('university', 'NN'),\n",
            " ('rejected', 'VBD'),\n",
            " ('them', 'PPO'),\n",
            " ('on', 'IN'),\n",
            " ('a', 'AT'),\n",
            " ('variety', 'NN'),\n",
            " ('of', 'IN'),\n",
            " ('pretexts', 'NNS'),\n",
            " (',', ','),\n",
            " ('but', 'CC'),\n",
            " ('was', 'BEDZ'),\n",
            " ('careful', 'JJ'),\n",
            " ('never', 'RB'),\n",
            " ('to', 'TO'),\n",
            " ('mention', 'VB'),\n",
            " ('the', 'AT'),\n",
            " ('color', 'NN'),\n",
            " ('of', 'IN'),\n",
            " ('their', 'PP$'),\n",
            " ('skins', 'NNS'),\n",
            " ('.', '.')]\n",
            "Etiquetas predichas por el modelo HMM:\n",
            "[('The', 'AT'),\n",
            " ('university', 'NN'),\n",
            " ('rejected', 'VBD'),\n",
            " ('them', 'PPO'),\n",
            " ('on', 'IN'),\n",
            " ('a', 'AT'),\n",
            " ('variety', 'NN'),\n",
            " ('of', 'IN'),\n",
            " ('pretexts', 'NP'),\n",
            " (',', ','),\n",
            " ('but', 'CC'),\n",
            " ('was', 'BEDZ'),\n",
            " ('careful', 'VBN'),\n",
            " ('never', 'RB'),\n",
            " ('to', 'TO'),\n",
            " ('mention', 'VB'),\n",
            " ('the', 'AT'),\n",
            " ('color', 'NN'),\n",
            " ('of', 'IN'),\n",
            " ('their', 'PP$'),\n",
            " ('skins', 'NN'),\n",
            " ('.', '.')]\n",
            "\n",
            "Matriz de Confusión para esta oración:\n",
            "     |       B                           |\n",
            "     |       E         N   P P       V V |\n",
            "     |     A D C I J N N N P P R T V B B |\n",
            "     | , . T Z C N J N S P $ O B O B D N |\n",
            "-----+-----------------------------------+\n",
            "   , |<1>. . . . . . . . . . . . . . . . |\n",
            "   . | .<1>. . . . . . . . . . . . . . . |\n",
            "  AT | . .<3>. . . . . . . . . . . . . . |\n",
            "BEDZ | . . .<1>. . . . . . . . . . . . . |\n",
            "  CC | . . . .<1>. . . . . . . . . . . . |\n",
            "  IN | . . . . .<3>. . . . . . . . . . . |\n",
            "  JJ | . . . . . .<.>. . . . . . . . . 1 |\n",
            "  NN | . . . . . . .<3>. . . . . . . . . |\n",
            " NNS | . . . . . . . 1<.>1 . . . . . . . |\n",
            "  NP | . . . . . . . . .<.>. . . . . . . |\n",
            " PP$ | . . . . . . . . . .<1>. . . . . . |\n",
            " PPO | . . . . . . . . . . .<1>. . . . . |\n",
            "  RB | . . . . . . . . . . . .<1>. . . . |\n",
            "  TO | . . . . . . . . . . . . .<1>. . . |\n",
            "  VB | . . . . . . . . . . . . . .<1>. . |\n",
            " VBD | . . . . . . . . . . . . . . .<1>. |\n",
            " VBN | . . . . . . . . . . . . . . . .<.>|\n",
            "-----+-----------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "Precisión para esta oración específica: 0.8636\n",
            "\n",
            "--- Evaluación detallada para la oración con índice 76 del conjunto de pruebas ---\n",
            "Oración original (palabras): Why did the Belgians grant independence to a colony so manifestly unprepared to accept it ? ?\n",
            "Etiquetas reales (gold standard):\n",
            "[('Why', 'WRB'),\n",
            " ('did', 'DOD'),\n",
            " ('the', 'AT'),\n",
            " ('Belgians', 'NPS'),\n",
            " ('grant', 'VB'),\n",
            " ('independence', 'NN'),\n",
            " ('to', 'IN'),\n",
            " ('a', 'AT'),\n",
            " ('colony', 'NN'),\n",
            " ('so', 'QL'),\n",
            " ('manifestly', 'RB'),\n",
            " ('unprepared', 'JJ'),\n",
            " ('to', 'TO'),\n",
            " ('accept', 'VB'),\n",
            " ('it', 'PPO'),\n",
            " ('?', '.'),\n",
            " ('?', '.')]\n",
            "Etiquetas predichas por el modelo HMM:\n",
            "[('Why', 'WRB'),\n",
            " ('did', 'DOD'),\n",
            " ('the', 'AT'),\n",
            " ('Belgians', 'JJ'),\n",
            " ('grant', 'NN'),\n",
            " ('independence', 'NN'),\n",
            " ('to', 'IN'),\n",
            " ('a', 'AT'),\n",
            " ('colony', 'NN'),\n",
            " ('so', 'CS'),\n",
            " ('manifestly', 'PPS'),\n",
            " ('unprepared', 'VBD'),\n",
            " ('to', 'TO'),\n",
            " ('accept', 'VB'),\n",
            " ('it', 'PPO'),\n",
            " ('?', '.'),\n",
            " ('?', '.')]\n",
            "\n",
            "Matriz de Confusión para esta oración:\n",
            "    |       D       N P P         V W |\n",
            "    |   A C O I J N P P P Q R T V B R |\n",
            "    | . T S D N J N S O S L B O B D B |\n",
            "----+---------------------------------+\n",
            "  . |<2>. . . . . . . . . . . . . . . |\n",
            " AT | .<2>. . . . . . . . . . . . . . |\n",
            " CS | . .<.>. . . . . . . . . . . . . |\n",
            "DOD | . . .<1>. . . . . . . . . . . . |\n",
            " IN | . . . .<1>. . . . . . . . . . . |\n",
            " JJ | . . . . .<.>. . . . . . . . 1 . |\n",
            " NN | . . . . . .<2>. . . . . . . . . |\n",
            "NPS | . . . . . 1 .<.>. . . . . . . . |\n",
            "PPO | . . . . . . . .<1>. . . . . . . |\n",
            "PPS | . . . . . . . . .<.>. . . . . . |\n",
            " QL | . . 1 . . . . . . .<.>. . . . . |\n",
            " RB | . . . . . . . . . 1 .<.>. . . . |\n",
            " TO | . . . . . . . . . . . .<1>. . . |\n",
            " VB | . . . . . . 1 . . . . . .<1>. . |\n",
            "VBD | . . . . . . . . . . . . . .<.>. |\n",
            "WRB | . . . . . . . . . . . . . . .<1>|\n",
            "----+---------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "Precisión para esta oración específica: 0.7059\n",
            "\n",
            "--- Evaluación detallada para la oración con índice 150 del conjunto de pruebas ---\n",
            "Oración original (palabras): And that was not all .\n",
            "Etiquetas reales (gold standard):\n",
            "[('And', 'CC'),\n",
            " ('that', 'DT'),\n",
            " ('was', 'BEDZ'),\n",
            " ('not', '*'),\n",
            " ('all', 'ABN'),\n",
            " ('.', '.')]\n",
            "Etiquetas predichas por el modelo HMM:\n",
            "[('And', 'CC'),\n",
            " ('that', 'DT'),\n",
            " ('was', 'BEDZ'),\n",
            " ('not', '*'),\n",
            " ('all', 'ABN'),\n",
            " ('.', '.')]\n",
            "\n",
            "Matriz de Confusión para esta oración:\n",
            "     |       B     |\n",
            "     |     A E     |\n",
            "     |     B D C D |\n",
            "     | * . N Z C T |\n",
            "-----+-------------+\n",
            "   * |<1>. . . . . |\n",
            "   . | .<1>. . . . |\n",
            " ABN | . .<1>. . . |\n",
            "BEDZ | . . .<1>. . |\n",
            "  CC | . . . .<1>. |\n",
            "  DT | . . . . .<1>|\n",
            "-----+-------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "Precisión para esta oración específica: 1.0000\n",
            "\n",
            "--- Evaluación detallada para la oración con índice 200 del conjunto de pruebas ---\n",
            "Oración original (palabras): The father , by accident or perhaps to show , as he said , `` we mean business '' , took the and fired a slug between the legs of Second Officer Norman Simmons .\n",
            "Etiquetas reales (gold standard):\n",
            "[('The', 'AT'),\n",
            " ('father', 'NN'),\n",
            " (',', ','),\n",
            " ('by', 'IN'),\n",
            " ('accident', 'NN'),\n",
            " ('or', 'CC'),\n",
            " ('perhaps', 'RB'),\n",
            " ('to', 'TO'),\n",
            " ('show', 'VB'),\n",
            " (',', ','),\n",
            " ('as', 'CS'),\n",
            " ('he', 'PPS'),\n",
            " ('said', 'VBD'),\n",
            " (',', ','),\n",
            " ('``', '``'),\n",
            " ('we', 'PPSS'),\n",
            " ('mean', 'VB'),\n",
            " ('business', 'NN'),\n",
            " (\"''\", \"''\"),\n",
            " (',', ','),\n",
            " ('took', 'VBD'),\n",
            " ('the', 'AT'),\n",
            " ('and', 'CC'),\n",
            " ('fired', 'VBD'),\n",
            " ('a', 'AT'),\n",
            " ('slug', 'NN'),\n",
            " ('between', 'IN'),\n",
            " ('the', 'AT'),\n",
            " ('legs', 'NNS'),\n",
            " ('of', 'IN'),\n",
            " ('Second', 'OD-TL'),\n",
            " ('Officer', 'NN-TL'),\n",
            " ('Norman', 'NP'),\n",
            " ('Simmons', 'NP'),\n",
            " ('.', '.')]\n",
            "Etiquetas predichas por el modelo HMM:\n",
            "[('The', 'AT'),\n",
            " ('father', 'NN'),\n",
            " (',', ','),\n",
            " ('by', 'IN'),\n",
            " ('accident', 'NN'),\n",
            " ('or', 'CC'),\n",
            " ('perhaps', 'RB'),\n",
            " ('to', 'TO'),\n",
            " ('show', 'VB'),\n",
            " (',', ','),\n",
            " ('as', 'CS'),\n",
            " ('he', 'PPS'),\n",
            " ('said', 'VBD'),\n",
            " (',', ','),\n",
            " ('``', '``'),\n",
            " ('we', 'PPSS'),\n",
            " ('mean', 'VB'),\n",
            " ('business', 'NN'),\n",
            " (\"''\", \"''\"),\n",
            " (',', ','),\n",
            " ('took', 'VBD'),\n",
            " ('the', 'AT'),\n",
            " ('and', 'CC'),\n",
            " ('fired', 'VBD'),\n",
            " ('a', 'AT'),\n",
            " ('slug', 'NN'),\n",
            " ('between', 'IN'),\n",
            " ('the', 'AT'),\n",
            " ('legs', 'NNS'),\n",
            " ('of', 'IN'),\n",
            " ('Second', 'NP'),\n",
            " ('Officer', 'NP'),\n",
            " ('Norman', 'NP'),\n",
            " ('Simmons', '.'),\n",
            " ('.', '.')]\n",
            "\n",
            "Matriz de Confusión para esta oración:\n",
            "      |                 N     O               |\n",
            "      |                 N     D   P           |\n",
            "      |                 - N   - P P       V   |\n",
            "      | '     A C C I N T N N T P S R T V B ` |\n",
            "      | ' , . T C S N N L S P L S S B O B D ` |\n",
            "------+---------------------------------------+\n",
            "   '' |<1>. . . . . . . . . . . . . . . . . . |\n",
            "    , | .<4>. . . . . . . . . . . . . . . . . |\n",
            "    . | . .<1>. . . . . . . . . . . . . . . . |\n",
            "   AT | . . .<4>. . . . . . . . . . . . . . . |\n",
            "   CC | . . . .<2>. . . . . . . . . . . . . . |\n",
            "   CS | . . . . .<1>. . . . . . . . . . . . . |\n",
            "   IN | . . . . . .<3>. . . . . . . . . . . . |\n",
            "   NN | . . . . . . .<4>. . . . . . . . . . . |\n",
            "NN-TL | . . . . . . . .<.>. 1 . . . . . . . . |\n",
            "  NNS | . . . . . . . . .<1>. . . . . . . . . |\n",
            "   NP | . . 1 . . . . . . .<1>. . . . . . . . |\n",
            "OD-TL | . . . . . . . . . . 1<.>. . . . . . . |\n",
            "  PPS | . . . . . . . . . . . .<1>. . . . . . |\n",
            " PPSS | . . . . . . . . . . . . .<1>. . . . . |\n",
            "   RB | . . . . . . . . . . . . . .<1>. . . . |\n",
            "   TO | . . . . . . . . . . . . . . .<1>. . . |\n",
            "   VB | . . . . . . . . . . . . . . . .<2>. . |\n",
            "  VBD | . . . . . . . . . . . . . . . . .<3>. |\n",
            "   `` | . . . . . . . . . . . . . . . . . .<1>|\n",
            "------+---------------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n",
            "Precisión para esta oración específica: 0.9143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion sobre esta oracion sobre el rendimiento del modelo HMM sobre el indice 200 del conjunto de pruebas como ejemplo de análisis."
      ],
      "metadata": {
        "id": "am3eczfJHasi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo ha demostrado una gran precisión al identificar la mayoría de las palabras dentro de la oración. En particular, ha manejado con éxito etiquetas correspondientes a partes del discurso que son más comunes y predecibles, como determinantes (AT), sustantivos comunes (NN), verbos (VB, VBD), preposiciones (IN), conjunciones (CC), adverbios (RB) y pronombres (PPS, PPSS). Además, ha reconocido correctamente la puntuación básica.\n",
        "\n",
        "Sin embargo, se identificaron errores en algunas palabras específicas:\n",
        "\n",
        "- **Second:** La etiqueta correcta era OD-TL (Ordinal en Título), pero el modelo la clasificó como NP (Nombre Propio). Este error podría deberse a que el modelo interpretó \"Second Officer\" como parte de un nombre propio compuesto (ej. Norman Simmons). Otra posibilidad es que las etiquetas OD-TL sean menos frecuentes en el corpus de entrenamiento, lo que hace más difícil su correcta identificación.\n",
        "\n",
        "- **Officer:** La etiqueta real en el corpus era NN-TL (Sustantivo en Título), pero el modelo también la clasificó como NP. Esto confirma la tendencia del modelo a agrupar palabras capitalizadas dentro de un contexto de título o nombre propio, simplificándolas como NP. Las etiquetas con el sufijo \"-TL\" son más específicas y pueden ser difíciles de distinguir si el modelo no ha sido expuesto a suficientes ejemplos de este tipo en el entrenamiento.\n",
        "\n",
        "- **Simmons:** Este fue un error crítico. La etiqueta correcta era NP (Nombre Propio), pero el modelo predijo \".\" (Puntuación). Este tipo de fallo podría indicar que el modelo no identificó correctamente el final de la secuencia de nombre propio, o que hubo un problema en la representación contextual de la palabra. Es posible que el modelo haya esperado una puntuación al final de la oración y, por error, haya asociado esa expectativa con \"Simmons\".\n",
        "\n",
        "En resumen, aunque el modelo ha aprendido bien los patrones generales del lenguaje, todavía tiene dificultades con ciertas palabras que poseen etiquetas más específicas o menos frecuentes en el corpus de entrenamiento."
      ],
      "metadata": {
        "id": "h6eEHd8xHfEU"
      }
    }
  ]
}